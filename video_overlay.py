#!/usr/bin/env python3
"""Video MC Overlay - Gh√©p MC v√†o video n·ªÅn v·ªõi x·ª≠ l√Ω l·ªói c·∫£i ti·∫øn"""

import cv2
import sys
import subprocess
import tempfile
import os
import shutil
import json
import argparse
from PIL import Image
import torch
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor
from functools import lru_cache
import numpy as np

class VideoOverlay:
    def __init__(self, mc_video, bg_video, position='G√≥c d∆∞·ªõi ph·∫£i', scale=0.25, output=None, quality='medium', bitrate=None):
        self.mc_video = Path(mc_video)
        self.bg_video = Path(bg_video)
        self.position = position
        self.scale = scale
        self.output = Path(output or f"{self.mc_video.parent}/output_{self.mc_video.stem}_{self.bg_video.stem}.mp4")
        self.quality = {'low': 'ultrafast', 'medium': 'medium', 'high': 'slow'}.get(quality, quality)
        self.temp_dir = Path(tempfile.mkdtemp())
        self.frames_dir = self.temp_dir / "frames"
        self.frames_dir.mkdir(exist_ok=True)
        
        # Ki·ªÉm tra file input t·ªìn t·∫°i
        if not self.mc_video.exists():
            raise FileNotFoundError(f"MC video kh√¥ng t·ªìn t·∫°i: {self.mc_video}")
        if not self.bg_video.exists():
            raise FileNotFoundError(f"Background video kh√¥ng t·ªìn t·∫°i: {self.bg_video}")
        
        # Kh·ªüi t·∫°o transparent background remover
        try:
            from transparent_background import Remover
            self.device = "cuda" if torch.cuda.is_available() else "cpu"
            self.remover = Remover(mode='fast', device=self.device)
            self.use_ai_bg_removal = True
        except ImportError:
            print("‚ö†Ô∏è transparent-background kh√¥ng c√≥, s·ª≠ d·ª•ng ch·∫ø ƒë·ªô fallback")
            self.use_ai_bg_removal = False
        
        # L·∫•y th√¥ng tin video
        self.mc_info = self._get_video_info(str(mc_video))
        self.bg_info = self._get_video_info(str(bg_video))
        
        # X·ª≠ l√Ω th√¥ng tin video an to√†n
        self.mc_fps = self._extract_fps(self.mc_info.get('r_frame_rate', '30/1'))
        self.bg_width = int(self.bg_info.get('width', 1280))
        self.bg_height = int(self.bg_info.get('height', 720))
        
        # Ki·ªÉm tra audio streams
        self.has_audio = {
            'mc': self._has_audio_stream(str(mc_video)),
            'bg': self._has_audio_stream(str(bg_video))
        }
        
        self.bitrate = bitrate or f"{max(1, int(self.bg_width * self.bg_height * self.mc_fps / 500000))}M"

    def _extract_fps(self, fps_str):
        """Tr√≠ch xu·∫•t FPS t·ª´ string m·ªôt c√°ch an to√†n"""
        try:
            if '/' in fps_str:
                nums = fps_str.split('/')
                return float(nums[0]) / float(nums[1]) if len(nums) == 2 and float(nums[1]) != 0 else 30.0
            return float(fps_str)
        except:
            return 30.0

    def _has_audio_stream(self, video_path):
        """Ki·ªÉm tra xem video c√≥ audio stream kh√¥ng"""
        try:
            cmd = f'ffprobe -v error -select_streams a -show_entries stream=codec_type -of json "{video_path}"'
            result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
            if result.returncode == 0:
                data = json.loads(result.stdout)
                return len(data.get('streams', [])) > 0
        except:
            pass
        return False

    def __del__(self):
        """Cleanup temp directory"""
        if hasattr(self, 'temp_dir') and self.temp_dir.exists():
            shutil.rmtree(self.temp_dir, ignore_errors=True)

    @lru_cache(maxsize=4)
    def _get_video_info(self, video_path):
        """L·∫•y th√¥ng tin video v·ªõi cache"""
        cmd = f'ffprobe -v error -select_streams v:0 -show_entries stream=width,height,r_frame_rate -of json "{video_path}"'
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
        
        if result.returncode == 0 and result.stdout.strip():
            try:
                data = json.loads(result.stdout)
                streams = data.get('streams', [{}])
                return streams[0] if streams else {}
            except:
                pass
        return {}

    def process(self):
        """X·ª≠ l√Ω video overlay v·ªõi nhi·ªÅu ph∆∞∆°ng √°n fallback"""
        
        # Ki·ªÉm tra xem MC l√† ·∫£nh hay video
        mc_ext = self.mc_video.suffix.lower()
        is_image = mc_ext in ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']
        
        if is_image:
            return self._process_image_mc()
        else:
            return self._process_video_mc()
    
    def _process_image_mc(self):
        """X·ª≠ l√Ω khi MC input l√† ·∫£nh"""
        try:
            # ƒê·ªçc ·∫£nh MC
            mc_img = cv2.imread(str(self.mc_video))
            if mc_img is None:
                return "L·ªói: Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh MC", None
            
            # X·ª≠ l√Ω background removal n·∫øu c√≥ th·ªÉ
            if self.use_ai_bg_removal:
                try:
                    # Chuy·ªÉn BGR sang RGB cho PIL
                    mc_rgb = cv2.cvtColor(mc_img, cv2.COLOR_BGR2RGB)
                    pil_img = Image.fromarray(mc_rgb)
                    
                    # Remove background
                    mc_transparent = self.remover.process(pil_img, type="rgba")
                    
                    # Chuy·ªÉn v·ªÅ numpy array
                    mc_array = np.array(mc_transparent)
                    
                    # T·∫°o frame v·ªõi alpha channel
                    overlay_frame = mc_array
                    
                except Exception as e:
                    print(f"‚ö†Ô∏è AI background removal failed, using original: {e}")
                    # Fallback: s·ª≠ d·ª•ng ·∫£nh g·ªëc
                    overlay_frame = cv2.cvtColor(mc_img, cv2.COLOR_BGR2RGBA)
            else:
                # Kh√¥ng c√≥ AI removal, s·ª≠ d·ª•ng ·∫£nh g·ªëc
                overlay_frame = cv2.cvtColor(mc_img, cv2.COLOR_BGR2RGBA)
            
            # L∆∞u frame overlay
            overlay_path = self.temp_dir / "overlay.png"
            if overlay_frame.shape[2] == 4:  # RGBA
                Image.fromarray(overlay_frame).save(overlay_path)
            else:  # RGB
                cv2.imwrite(str(overlay_path), overlay_frame)
            
            # T·∫°o video overlay v·ªõi FFmpeg
            return self._create_overlay_video(overlay_path, is_static=True)
            
        except Exception as e:
            return f"L·ªói x·ª≠ l√Ω ·∫£nh MC: {str(e)}", None
    
    def _process_video_mc(self):
        """X·ª≠ l√Ω khi MC input l√† video"""
        if not self._process_frames():
            return "L·ªói: Kh√¥ng th·ªÉ x·ª≠ l√Ω frames video", None
        
        # S·ª≠ d·ª•ng frames ƒë√£ x·ª≠ l√Ω
        return self._create_overlay_video(self.frames_dir / "f_%06d.png", is_static=False)
    
    def _process_frames(self):
        """X·ª≠ l√Ω t·ª´ng frame c·ªßa video MC"""
        cap = cv2.VideoCapture(str(self.mc_video))
        if not cap.isOpened():
            return False

        frame_count = 0
        success_count = 0
        
        with ThreadPoolExecutor(max_workers=min(os.cpu_count() or 2, 8)) as executor:
            futures = []
            
            while cap.isOpened():
                ret, frame = cap.read()
                if not ret:
                    break
                
                future = executor.submit(self._process_frame, frame, frame_count)
                futures.append(future)
                frame_count += 1
            
            cap.release()
            
            # ƒê·ª£i t·∫•t c·∫£ frames x·ª≠ l√Ω xong
            for future in futures:
                if future.result():
                    success_count += 1
        
        print(f"‚úÖ ƒê√£ x·ª≠ l√Ω {success_count}/{frame_count} frames")
        return success_count > 0

    def _process_frame(self, frame, idx):
        """X·ª≠ l√Ω m·ªôt frame v·ªõi background removal"""
        try:
            if frame is None:
                return False
            
            if self.use_ai_bg_removal:
                # Chuy·ªÉn BGR sang RGB cho PIL
                rgb_img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                pil_img = Image.fromarray(rgb_img)
                
                # Remove background
                result = self.remover.process(pil_img, type="rgba")
                result.save(self.frames_dir / f'f_{idx:06d}.png')
            else:
                # Fallback: l∆∞u frame g·ªëc
                cv2.imwrite(str(self.frames_dir / f'f_{idx:06d}.png'), frame)
            
            return True
            
        except Exception as e:
            print(f"‚ö†Ô∏è L·ªói x·ª≠ l√Ω frame {idx}: {e}")
            return False

    def _create_overlay_video(self, overlay_input, is_static=False):
        """T·∫°o video overlay v·ªõi FFmpeg"""
        
        # X√°c ƒë·ªãnh v·ªã tr√≠ overlay
        positions = {
            "G√≥c tr√™n tr√°i": "0:0",
            "G√≥c tr√™n ph·∫£i": f"{self.bg_width}-overlay_w:0", 
            "G√≥c d∆∞·ªõi tr√°i": f"0:{self.bg_height}-overlay_h",
            "G√≥c d∆∞·ªõi ph·∫£i": f"{self.bg_width}-overlay_w:{self.bg_height}-overlay_h",
            "Ch√≠nh gi·ªØa": f"({self.bg_width}-overlay_w)/2:({self.bg_height}-overlay_h)/2"
        }
        pos = positions.get(self.position, positions["G√≥c d∆∞·ªõi ph·∫£i"])
        
        # T·∫°o filter complex
        if is_static:
            # Cho ·∫£nh tƒ©nh
            filter_complex = f"[1]scale=iw*{self.scale}:-1[overlay];[0:v][overlay]overlay={pos}:enable='between(t,0,{self._get_bg_duration()})'"
        else:
            # Cho video frames
            filter_complex = f"[1]scale=iw*{self.scale}:-1[overlay];[0:v][overlay]overlay={pos}"
        
        # L·ªánh FFmpeg ch√≠nh
        if is_static:
            cmd = [
                'ffmpeg', '-y',
                '-i', str(self.bg_video),  # Background video
                '-loop', '1', '-i', str(overlay_input),  # Static overlay image
                '-filter_complex', filter_complex,
                '-shortest',  # End when shortest input ends
                '-c:v', 'libx264', '-preset', self.quality, '-crf', '23',
                '-pix_fmt', 'yuv420p'
            ]
        else:
            cmd = [
                'ffmpeg', '-y',
                '-i', str(self.bg_video),  # Background video
                '-framerate', str(self.mc_fps), '-i', str(overlay_input),  # Overlay frames
                '-filter_complex', filter_complex,
                '-c:v', 'libx264', '-preset', self.quality, '-crf', '23',
                '-pix_fmt', 'yuv420p'
            ]
        
        # X·ª≠ l√Ω audio
        if self.has_audio['mc'] and not is_static:
            # ∆Øu ti√™n audio t·ª´ MC n·∫øu c√≥
            cmd.extend(['-i', str(self.mc_video), '-map', '2:a', '-c:a', 'aac', '-b:a', '192k'])
        elif self.has_audio['bg']:
            # S·ª≠ d·ª•ng audio t·ª´ background
            cmd.extend(['-map', '0:a', '-c:a', 'aac', '-b:a', '192k'])
        else:
            # Kh√¥ng c√≥ audio
            cmd.append('-an')
        
        # Th√™m output path
        cmd.append(str(self.output))
        
        # Ch·∫°y l·ªánh
        print(f"üîÑ ƒêang t·∫°o video overlay...")
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode == 0 and self.output.exists() and self.output.stat().st_size > 0:
            size_mb = self.output.stat().st_size / (1024 * 1024)
            return f"‚úÖ T·∫°o video th√†nh c√¥ng! ({size_mb:.2f} MB)", str(self.output)
        
        # Fallback method
        print("‚ö†Ô∏è Ph∆∞∆°ng ph√°p ch√≠nh th·∫•t b·∫°i, th·ª≠ ph∆∞∆°ng √°n d·ª± ph√≤ng...")
        return self._fallback_overlay()
    
    def _fallback_overlay(self):
        """Ph∆∞∆°ng √°n d·ª± ph√≤ng ƒë∆°n gi·∫£n h∆°n"""
        try:
            # L·ªánh ƒë∆°n gi·∫£n h∆°n
            cmd = [
                'ffmpeg', '-y',
                '-i', str(self.bg_video),
                '-i', str(self.mc_video),
                '-filter_complex', f'[1:v]scale=iw*{self.scale}:-1[overlay];[0:v][overlay]overlay=W-w-10:H-h-10',
                '-c:v', 'libx264', '-preset', 'ultrafast', '-crf', '28'
            ]
            
            # Audio handling
            if self.has_audio['bg']:
                cmd.extend(['-map', '0:a', '-c:a', 'copy'])
            else:
                cmd.append('-an')
            
            cmd.append(str(self.output))
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode == 0 and self.output.exists() and self.output.stat().st_size > 0:
                size_mb = self.output.stat().st_size / (1024 * 1024)
                return f"‚úÖ T·∫°o video th√†nh c√¥ng (fallback)! ({size_mb:.2f} MB)", str(self.output)
            else:
                return f"‚ùå L·ªói t·∫°o video: {result.stderr}", None
                
        except Exception as e:
            return f"‚ùå L·ªói fallback: {str(e)}", None
    
    def _get_bg_duration(self):
        """L·∫•y ƒë·ªô d√†i c·ªßa background video"""
        try:
            cmd = f'ffprobe -v error -show_entries format=duration -of default=noprint_wrappers=1:nokey=1 "{self.bg_video}"'
            result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
            if result.returncode == 0:
                return float(result.stdout.strip())
        except:
            pass
        return 10.0  # Default 10 seconds

def main():
    """H√†m ch√≠nh ƒë·ªÉ ch·∫°y t·ª´ command line"""
    parser = argparse.ArgumentParser(description="Video MC Overlay - Gh√©p MC v√†o video n·ªÅn")
    parser.add_argument('-m', '--mc-video', required=True, help='Video/·∫¢nh MC')
    parser.add_argument('-b', '--bg-video', required=True, help='Video n·ªÅn')
    parser.add_argument('-o', '--output', help='File ƒë·∫ßu ra')
    parser.add_argument('-p', '--position', default='G√≥c d∆∞·ªõi ph·∫£i', 
                       choices=["G√≥c tr√™n tr√°i", "G√≥c tr√™n ph·∫£i", "G√≥c d∆∞·ªõi tr√°i", "G√≥c d∆∞·ªõi ph·∫£i", "Ch√≠nh gi·ªØa"])
    parser.add_argument('-s', '--scale', type=float, default=0.25, help='T·ª∑ l·ªá (0.1-0.5)')
    parser.add_argument('-q', '--quality', default='medium', 
                       choices=['low', 'medium', 'high', 'ultrafast', 'slow', 'veryslow'])
    parser.add_argument('-r', '--bitrate', help='Bitrate (VD: 4M)')

    args = parser.parse_args()
    
    # Ki·ªÉm tra t·ª∑ l·ªá scale
    if not (0.1 <= args.scale <= 0.5):
        print("‚ùå T·ª∑ l·ªá scale ph·∫£i n·∫±m trong kho·∫£ng 0.1-0.5")
        return 1

    # Ki·ªÉm tra FFmpeg
    if subprocess.run("ffmpeg -version", shell=True, capture_output=True).returncode != 0:
        print("‚ùå FFmpeg kh√¥ng ƒë∆∞·ª£c t√¨m th·∫•y. Vui l√≤ng c√†i ƒë·∫∑t FFmpeg.")
        return 1

    try:
        overlay = VideoOverlay(
            args.mc_video, args.bg_video, args.position, 
            args.scale, args.output, args.quality, args.bitrate
        )
        status, output = overlay.process()

        print(f"\n{'‚úÖ' if output else '‚ùå'} {status}")
        if output:
            print(f"üìÅ File: {output}")
        return 0 if output else 1
        
    except Exception as e:
        print(f"‚ùå L·ªói: {str(e)}")
        return 1

if __name__ == "__main__":
    sys.exit(main())

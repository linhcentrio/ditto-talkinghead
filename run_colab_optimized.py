#!/usr/bin/env python3
"""
ğŸ­ Ditto Talking Head - Optimized Setup (Sá»­ dá»¥ng Pre-loaded Environment)
Cháº¡y vá»›i environment Ä‘Ã£ load tá»« Google Drive vÃ  táº£i models tá»« HuggingFace
"""

import os
import sys
import subprocess
import time
import threading
import requests
import shutil
from pathlib import Path

# =================== SIMPLIFIED LOGGER ===================
class ProgressLogger:
    def __init__(self, total_steps=6):  # Giáº£m tá»« 8 xuá»‘ng 6 steps
        self.total_steps = total_steps
        self.current_step = 0
        self.start_time = time.time()

    def log_step(self, step_name, status="progress"):
        if status == "progress":
            self.current_step += 1
            percent = (self.current_step / self.total_steps) * 100
            print(f"[{percent:.0f}%] {step_name}...")
        elif status == "success":
            print(f"âœ… {step_name}")
        elif status == "error":
            print(f"âŒ {step_name}")

# Import cÃ¡c thÆ° viá»‡n Ä‘Ã£ cÃ³ trong environment
try:
    from pyngrok import ngrok
    import torch
    import streamlit
    print("âœ… Environment imports successful")
except ImportError as e:
    print(f"âŒ Environment import error: {e}")
    print("ğŸ’¡ Vui lÃ²ng load persistent environment trÆ°á»›c")
    sys.exit(1)

# =================== CONSTANTS ===================
REPO_URL = "https://github.com/linhcentrio/ditto-talkinghead.git"
REPO_BRANCH = "colab"
HUGGINGFACE_CONFIG_URL = "https://huggingface.co/digital-avatar/ditto-talkinghead/resolve/main/ditto_cfg/v0.4_hubert_cfg_trt.pkl"
HUGGINGFACE_MODELS_REPO = "manh-linh/ditto_trt_custom"  # Tá»« search results[1]

class DittoOptimizedSetup:
    def __init__(self):
        self.start_time = time.time()
        self.gpu_capability = 6
        self.data_root = "./checkpoints/ditto_trt"
        self.streamlit_process = None
        self.ngrok_tunnel = None
        self.logger = ProgressLogger()
        
    def run_command_silent(self, cmd, timeout=300):
        """Cháº¡y lá»‡nh im láº·ng"""
        try:
            result = subprocess.run(
                cmd, shell=True, capture_output=True, 
                text=True, timeout=timeout
            )
            return result.returncode == 0
        except:
            return False
    
    def check_system(self):
        """Kiá»ƒm tra há»‡ thá»‘ng vÃ  GPU"""
        try:
            if torch.cuda.is_available():
                self.gpu_capability = torch.cuda.get_device_capability()[0]
                gpu_name = torch.cuda.get_device_name(0)
                print(f"   â†’ GPU: {gpu_name} (Capability: {self.gpu_capability})")
            return True
        except:
            return True
    
    def setup_repository(self):
        """Clone repository (nhanh hÆ¡n vÃ¬ khÃ´ng cáº§n cÃ i dependencies)"""
        
        if os.path.exists("ditto-talkinghead"):
            shutil.rmtree("ditto-talkinghead")
            
        success = self.run_command_silent(
            f"git clone --single-branch --branch {REPO_BRANCH} {REPO_URL} > /dev/null 2>&1"
        )
        
        if not success:
            return False
            
        os.chdir("ditto-talkinghead")
        self.run_command_silent("git pull > /dev/null 2>&1")
        
        return True
    
    def download_models_from_huggingface(self):
        """Táº£i models tá»« HuggingFace thay vÃ¬ Google Drive"""
        
        print("   â†’ Táº¡o thÆ° má»¥c checkpoints...")
        os.makedirs("checkpoints/ditto_cfg", exist_ok=True)
        
        # Táº£i config file
        print("   â†’ Táº£i config tá»« HuggingFace...")
        success = self.run_command_silent(
            f"wget -q {HUGGINGFACE_CONFIG_URL} -O checkpoints/ditto_cfg/v0.4_hubert_cfg_trt.pkl"
        )
        
        if not success:
            success = self.run_command_silent(
                f"curl -L {HUGGINGFACE_CONFIG_URL} -o checkpoints/ditto_cfg/v0.4_hubert_cfg_trt.pkl > /dev/null 2>&1"
            )
        
        # Táº£i TRT models tá»« HuggingFace[1]
        print(f"   â†’ Táº£i TRT models tá»« HuggingFace: {HUGGINGFACE_MODELS_REPO}")
        
        if self.gpu_capability < 8:
            self.data_root = "./checkpoints/ditto_trt"
            print("   â†’ Sá»­ dá»¥ng Non-Ampere models")
        else:
            self.data_root = "./checkpoints/ditto_trt_Ampere_Plus"
            print("   â†’ Sá»­ dá»¥ng Ampere+ models")
            
        os.makedirs(self.data_root, exist_ok=True)
        
        # Sá»­ dá»¥ng huggingface-hub Ä‘á»ƒ táº£i models (Ä‘Ã£ cÃ³ trong environment)
        try:
            from huggingface_hub import snapshot_download
            
            print("   â†’ Downloading tá»« HuggingFace Hub...")
            snapshot_download(
                repo_id=HUGGINGFACE_MODELS_REPO,
                local_dir=self.data_root,
                repo_type="model"
            )
            print("   â†’ HuggingFace models downloaded thÃ nh cÃ´ng")
            
        except Exception as e:
            print(f"   â†’ Lá»—i download tá»« HuggingFace: {e}")
            # Fallback: sá»­ dá»¥ng git clone
            print("   â†’ Thá»­ git clone...")
            self.run_command_silent(
                f"git clone https://huggingface.co/{HUGGINGFACE_MODELS_REPO} {self.data_root} > /dev/null 2>&1"
            )
            
        return True
    
    def test_ai_core(self):
        """Test AI Core SDK"""
        try:
            sys.path.insert(0, os.getcwd())
            
            if not os.path.exists('inference.py'):
                print("   â†’ inference.py khÃ´ng tÃ¬m tháº¥y (sáº½ táº¡o basic version)")
                return True
                
            from inference import StreamSDK
            
            cfg_pkl = "./checkpoints/ditto_cfg/v0.4_hubert_cfg_trt.pkl"
            if not os.path.exists(cfg_pkl):
                print("   â†’ Config file missing")
                return False
                
            SDK = StreamSDK(cfg_pkl, self.data_root)
            print("   â†’ AI Core SDK initialized thÃ nh cÃ´ng")
            return True
            
        except Exception as e:
            print(f"   â†’ AI Core test warning: {e}")
            return True  # Continue anyway
    
    def setup_api_keys(self):
        """Kiá»ƒm tra API keys Ä‘Ã£ Ä‘Æ°á»£c thiáº¿t láº­p"""
        
        ngrok_token = os.environ.get('NGROK_TOKEN', '').strip()
        
        if not ngrok_token:
            print("   â†’ Ngrok token missing!")
            return False
            
        try:
            ngrok.set_auth_token(ngrok_token)
            print("   â†’ Ngrok configured")
        except Exception as e:
            print(f"   â†’ Ngrok error: {e}")
            return False
            
        # Check optional keys
        openai_key = os.environ.get('OPENAI_API_KEY', '').strip()
        pexels_key = os.environ.get('PEXELS_API_KEY', '').strip()
        
        if openai_key:
            print("   â†’ OpenAI API available")
        else:
            print("   â†’ Using Edge TTS")
            
        if pexels_key:
            print("   â†’ Pexels API available")
            
        return True
    
    def create_streamlit_app(self):
        """Táº¡o Streamlit app optimized"""
        
        if os.path.exists("run_streamlit.py"):
            return True
            
        streamlit_code = '''
import streamlit as st
import sys
import os

# Add project path
sys.path.insert(0, os.getcwd())

st.set_page_config(
    page_title="ğŸ­ Ditto Talking Head",
    page_icon="ğŸ­",
    layout="wide"
)

st.title("ğŸ­ Ditto Talking Head")
st.markdown("### AI-Powered Talking Head Video Generator")
st.markdown("**Environment**: Pre-loaded tá»« Google Drive")

# Environment info
with st.sidebar:
    st.markdown("### ğŸ”§ Environment Info")
    st.markdown("âœ… Packages: Pre-loaded")
    st.markdown("âœ… Models: HuggingFace")
    st.markdown("âœ… GPU: Available" if torch.cuda.is_available() else "âš ï¸ GPU: Not available")

# Main UI
uploaded_file = st.file_uploader("Upload an image", type=['jpg', 'jpeg', 'png'])

if uploaded_file:
    st.image(uploaded_file, caption="Uploaded Image", width=300)
    
text_input = st.text_area("Enter text to speak:", height=100)

col1, col2 = st.columns(2)

with col1:
    voice_options = ["Edge TTS", "OpenAI TTS"]
    voice_choice = st.selectbox("Voice Engine:", voice_options)

with col2:
    language_options = ["Vietnamese", "English", "Chinese"]
    language = st.selectbox("Language:", language_options)

if st.button("ğŸ¬ Generate Talking Head Video", type="primary"):
    if uploaded_file and text_input:
        with st.spinner("ğŸ”„ Äang xá»­ lÃ½ video..."):
            st.info("ğŸš§ Video generation Ä‘ang Ä‘Æ°á»£c triá»ƒn khai")
            st.success("ğŸ‰ Demo UI ready! Chá»©c nÄƒng sáº½ Ä‘Æ°á»£c bá»• sung")
    else:
        st.warning("âš ï¸ Vui lÃ²ng upload áº£nh vÃ  nháº­p text")

# Footer
st.markdown("---")
st.markdown("### ğŸ”— Links")
col1, col2, col3 = st.columns(3)
with col1:
    st.markdown("[ğŸ”— GitHub](https://github.com/linhcentrio/ditto-talkinghead)")
with col2:
    st.markdown("[ğŸ¤— HuggingFace](https://huggingface.co/manh-linh/ditto_trt_custom)")
with col3:
    st.markdown("[ğŸŒ Ngrok Dashboard](https://dashboard.ngrok.com/)")
'''
        
        with open("run_streamlit.py", "w", encoding="utf-8") as f:
            f.write(streamlit_code)
            
        return True
    
    def start_streamlit_server(self):
        """Khá»Ÿi Ä‘á»™ng Streamlit (nhanh hÆ¡n vÃ¬ packages Ä‘Ã£ load)"""
        
        os.environ.update({
            'STREAMLIT_SERVER_FILE_WATCHER_TYPE': 'none',
            'STREAMLIT_SERVER_HEADLESS': 'true',
            'STREAMLIT_SERVER_PORT': '8501',
            'STREAMLIT_BROWSER_GATHER_USAGE_STATS': 'false'
        })
        
        if not self.create_streamlit_app():
            return False
            
        def run_streamlit():
            streamlit_cmd = [
                sys.executable, "-m", "streamlit", "run", "run_streamlit.py",
                "--server.port=8501", "--server.address=0.0.0.0", 
                "--server.headless=true", "--browser.gatherUsageStats=false",
                "--server.enableCORS=false", "--server.enableXsrfProtection=false"
            ]
            
            try:
                self.streamlit_process = subprocess.Popen(
                    streamlit_cmd, 
                    stdout=subprocess.DEVNULL, 
                    stderr=subprocess.DEVNULL
                )
                self.streamlit_process.wait()
            except:
                pass
                
        streamlit_thread = threading.Thread(target=run_streamlit, daemon=True)
        streamlit_thread.start()
        
        # Äá»£i server khá»Ÿi Ä‘á»™ng (nhanh hÆ¡n vÃ¬ packages Ä‘Ã£ load)
        print("   â†’ Waiting for Streamlit...")
        for attempt in range(8):  # Giáº£m tá»« 10 xuá»‘ng 8
            time.sleep(2)  # Giáº£m tá»« 3 xuá»‘ng 2 giÃ¢y
            try:
                response = requests.get("http://localhost:8501/_stcore/health", timeout=3)
                if response.status_code == 200:
                    print("   â†’ Streamlit ready")
                    return True
            except:
                continue
                
        return False
    
    def create_ngrok_tunnel(self):
        """Táº¡o Ngrok tunnel"""
        
        try:
            try:
                ngrok.kill()
                time.sleep(1)  # Giáº£m thá»i gian Ä‘á»£i
            except:
                pass
                
            self.ngrok_tunnel = ngrok.connect(8501, "http")
            public_url = str(self.ngrok_tunnel.public_url)
            
            print("\n" + "=" * 70)
            print("ğŸ‰ DITTO TALKING HEAD ÄÃƒ KHá»I Äá»˜NG THÃ€NH CÃ”NG!")
            print("=" * 70)
            print(f"ğŸ”— Public URL: {public_url}")
            print(f"ğŸ“± Truy cáº­p á»©ng dá»¥ng: {public_url}")
            print("ğŸš€ Environment: Pre-loaded tá»« Google Drive")
            print("ğŸ¤— Models: Loaded tá»« HuggingFace")
            print("â¹ï¸ Äá»ƒ dá»«ng: Ctrl+C hoáº·c restart runtime")
            print("=" * 70)
            
            try:
                while True:
                    time.sleep(30)
                    try:
                        requests.get(f"{public_url}/_stcore/health", timeout=5)
                    except:
                        pass
                        
            except KeyboardInterrupt:
                print("\nğŸ”„ Äang táº¯t á»©ng dá»¥ng...")
                self.cleanup()
                
            return True
            
        except Exception as e:
            print(f"âŒ Ngrok tunnel error: {str(e)}")
            return False
    
    def cleanup(self):
        """Cleanup resources"""
        try:
            if self.streamlit_process:
                self.streamlit_process.terminate()
            if self.ngrok_tunnel:
                ngrok.disconnect(self.ngrok_tunnel.public_url)
            ngrok.kill()
        except:
            pass
    
    def run_optimized_setup(self):
        """Cháº¡y setup tá»‘i Æ°u vá»›i environment Ä‘Ã£ load"""
        
        print("ğŸ­ Ditto Talking Head - Optimized Setup")
        print("ğŸš€ Sá»­ dá»¥ng Environment Ä‘Ã£ load")
        print("=" * 50)
        
        steps = [
            ("Kiá»ƒm tra há»‡ thá»‘ng", self.check_system),
            ("Thiáº¿t láº­p repository", self.setup_repository),
            ("Táº£i models tá»« HuggingFace", self.download_models_from_huggingface),
            ("Test AI Core", self.test_ai_core),
            ("Thiáº¿t láº­p API keys", self.setup_api_keys),
            ("Khá»Ÿi Ä‘á»™ng Streamlit", self.start_streamlit_server),
            ("Táº¡o Ngrok tunnel", self.create_ngrok_tunnel),
        ]
        
        try:
            for step_name, step_func in steps:
                self.logger.log_step(step_name, "progress")
                
                success = step_func()
                
                if not success:
                    self.logger.log_step(f"Lá»—i: {step_name}", "error")
                    return False
                    
            return True
            
        except KeyboardInterrupt:
            print("\nğŸ”„ Setup interrupted")
            return False
        except Exception as e:
            print(f"\nâŒ Error: {str(e)}")
            return False
        finally:
            if not self.ngrok_tunnel:
                self.cleanup()

def main():
    """Main function"""
    
    # Kiá»ƒm tra API keys
    ngrok_token = os.environ.get('NGROK_TOKEN', '').strip()
    
    if not ngrok_token:
        print("âŒ API Keys chÆ°a Ä‘Æ°á»£c thiáº¿t láº­p!")
        print("ğŸ’¡ Vui lÃ²ng cháº¡y cell 'Cáº¥u hÃ¬nh API Keys' trÆ°á»›c")
        sys.exit(1)
    
    # Kiá»ƒm tra environment Ä‘Ã£ load
    if '/content/packages' not in sys.path:
        print("âš ï¸ Environment cÃ³ thá»ƒ chÆ°a Ä‘Æ°á»£c load Ä‘Ãºng cÃ¡ch")
        print("ğŸ’¡ NhÆ°ng sáº½ tiáº¿p tá»¥c...")
    
    # Cháº¡y setup
    setup = DittoOptimizedSetup()
    
    success = setup.run_optimized_setup()
    
    if not success:
        print("\nâŒ Setup failed!")
        sys.exit(1)

if __name__ == "__main__":
    main()
